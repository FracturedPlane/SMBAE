{
"model_type": "Deep_CNN",
"agent_name": "CACLA",
"data_folder": "Simple_Walk_Forward_Dynamics/",
"epsilon": 0.45, 
"omega": 0.75,
"batch_size": 32,
"learning_rate": 0.001,
"anchor_file": "./learn/data/paperGibbonAnchors.json",
"sim_config_file": "./args/biped2D/test_biped_args.txt",
"forwardDynamics_config_file": "./args/biped2D/test_biped_args.txt",
"exploration_rate": 0.1,
"rounds": 4000,
"epochs": 5,
"eval_epochs": 5,
"num_states": 50,
"discount_factor": 0.95,
"visualize_learning": true,
"save_trainData": true,
"train_forward_dynamics": true,
"visulaize_forward_dynamics": true,
"reward_bounds": [[0.0],[1.0]],
"expereince_length": 10000,
"state_bounds": [[-3.14, 1.0,-8.05, -1.0, -1.0, -8.5, -5.0, -5.5, -5.0, -2.5, -3.14, 1.0,-8.05, -1.0, -1.0, -8.5, -5.0, -5.5, -5.0, -2.5, -3.14, 1.0,-8.05, -1.0, -1.0, -8.5, -5.0, -5.5, -5.0, -2.5, -3.14, 1.0,-8.05, -1.0, -1.0, -8.5, -5.0, -5.5, -5.0, -2.5, -3.14, 1.0,-8.05, -1.0, -1.0, -8.5, -5.0, -5.5, -5.0, -2.5, -3.14, 1.0,-8.05, -1.0, -1.0, -8.5, -5.0, -5.5, -5.0, -2.5, 0.0],
				 [ 3.14, 8.5, 5.00, 1.0, 1.0, 10.0, 5.0, 15.0,  5.0, 20.0, -3.14, 1.0,-8.05, -1.0, -1.0, -8.5, -5.0, -5.5, -5.0, -2.5, -3.14, 1.0,-8.05, -1.0, -1.0, -8.5, -5.0, -5.5, -5.0, -2.5, -3.14, 1.0,-8.05, -1.0, -1.0, -8.5, -5.0, -5.5, -5.0, -2.5, -3.14, 1.0,-8.05, -1.0, -1.0, -8.5, -5.0, -5.5, -5.0, -2.5, -3.14, 1.0,-8.05, -1.0, -1.0, -8.5, -5.0, -5.5, -5.0, -2.5, 1.0]],
				 
"action_bounds":    [[0.200000, 1.800000, -0.497252, -1.993935, 0.073527,-0.321481, 0.800288, -3.876833, -1.180141, -0.776967, -1.810372, -2.142646, -3.406771, 0.240827, -2.373369, -2.308333, -0.563421, -2.891676, -1.918455, -1.842994, -2.262842, 0.053321, -0.666870, -1.994344, 0.014701, -1.908623, -1.955703, 0.034434],
				     [0.351474, 2.300000,  0.097252, -0.693935, 1.873527, 3.121481, 2.500288, -2.576833, 0.580141,  0.176967, 0.610372,    0.642646, -0.006771, 2.240827, -0.573369, -0.008333,  0.863421, -1.091676,  0.418455, -0.242994,  0.262842, 0.853321, -0.166870, -0.494344, 1.394701, 0.908623, 1.655703, 2.634434]],
				     
"discrete_actions": [[0.251474, 2.099796, -0.097252, -0.993935, 0.273527, 0.221481, 1.100288, -3.076833, 0.180141, -0.176967, 0.310372, -1.642646,   -0.406771, 1.240827, -1.773369, -0.508333, -0.063421, -2.091676, -1.418455, -1.242994, -0.262842, 0.453321, -0.366870, -1.494344, 0.794701, -1.408623, 0.655703, 0.634434],
		             [0.316504, 1.963316, -0.325309, -1.802222, 1.668542, 2.453011, 2.139391, -3.636978, -0.855670, -0.350402, -1.342939, 0.337384, -3.272340, 2.048047, -0.938193, -1.799840,   0.384958, -2.357088,    0.076791, -1.513792, -1.855033, 0.340609, -0.400898, -0.903512, 0.144128, 0.524855, -1.534278, 1.856180 ],
		             [0.289427, 1.994835, -0.254906, -1.167773, 0.275834, -0.197735, 2.298369, -3.272985, -0.179217, -0.530879, -0.362771, -0.690035, -0.558768, 1.806804, -1.341557, -0.688935, 0.337809, -1.773089,   -1.025832, -0.472297, -0.766728, 0.358616, -0.481754, -1.328176, 0.498767, -0.236538, -0.471444, 1.154247]],
"action_space_continuous":true,
"train_on_validation_set":true,
"environment_type": "terrainRLBiped2D",
"forward_dynamics_predictor": "network",
"sampling_method": "SequentialMC",
"use_actor_policy_action_suggestion": true,
"num_uniform_action_samples": 3,
"look_ahead_planning_steps": 2,
"plotting_update_freq_num_rounds": 2,
"saving_update_freq_num_rounds": 2,
"num_available_threads": 1,
"queue_size_limit": 1,
"sim_action_per_training_update": 8,
"adaptive_samples": 5,
"num_adaptive_samples_to_keep": 50,
"use_actor_policy_action_variance_suggestion": false,
"exploration_method": "gaussian_random",
"dropout_p": 0.1,
"regularization_weight": 0.0001,
"rho": 0.95,
"rms_epsilon": 0.000001,
"steps_until_target_network_update": 1000,
"epsilon_annealing": 0.8,
"state_normalization": "variance",
    "comment__": "load a pretrained model for the controller",
"load_saved_model": false,
	"comment__": "Number of updates the critic should perform per actor update",
"critic_updates_per_actor_update": 5,
"clamp_actions_to_stay_inside_bounds": true,
"bootstrap_samples": 500,
"bootsrap_with_discrete_policy": true,
"max_epoch_length": 50,
"reward_lower_bound": -0.5,
"use_guided_policy_search" : false,
"training_updates_per_sim_action": 10,
"use_sampling_exploration": false,
"use_model_based_action_optimization": true,
"use_transfer_task_network": false,
"penalize_actions_outside_bounds": false,
"use_transfer_task_network": false,
"forward_dynamics_model_type": "Deep_CNN",
"save_experience_memory": false,
"train_rl_learning": true,
"use_back_on_track_forcing": false,
"visualize_forward_dynamics": false,
"fd_learning_rate": 0.01,
"train_actor": true,
"debug_critic": false,
"critic_regularization_weight": 0.000001,
"critic_learning_rate": 0.01,
"visualize_expected_value": true,
"target_velocity_decay":-0.75,
"target_velocity":3.0,
"num_terrain_features": 200
}